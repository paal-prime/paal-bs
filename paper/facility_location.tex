\chapter{Metrical Facility Location algorithms}

\section{Problem description}

Problem instance consists of a full bipartite graph $G = (F \cup C, F \times
C)$, where elements of $F$ are called \emph{facilities} and those of $C$ are
called \emph{cities}, $o : F \to \mathbb{R}$ being a cost function of opening
single facility and $c : F \times C \to \mathbb{R}$ being a cost function of
connecting facility with a city. The connection costs satisfy triangle
inequality.

The problem is to find a subset of facilities $O \subset F$ to be opened and an
assignment of cities to opened facilities $a : C \to O$ in such a way that the
total cost $\sum_{f \in O} o(f) + \sum_{c \in C} c(a(c), c)$ is minimized.

\section{Primal-dual schema 3-apx}
We have created efficient implementation of combinatoric approximation
algorithm for the problem as a reference point for other discussed methods. The
algorithm achieves a constant approximation factor of 3 and runs in $\Oh(|F||C|
\log(|F||C|))$ time. It operates in primal-dual fashion trying to find feasible
solution for dual problem with possibly the biggest cost. Detailed description
can be found in \cite{Vazirani}.

We have introduced a slight modification to original algorithm due to Jain and
Vasirani. Once the set of opened facilities is determined as in original
algorithm we create optimal assignment in $\Oh(|F||C|)$ time by assigning each
city to the closest facility. The assignment presented in original paper is
useful for estimating approximation factor of the algorithm though.

\section{Local Search 3-apx}

Local search with the following properties
guarantees\footnote{\url{http://www.cs.ucla.edu/~awm/papers/lsearch.ps}}
3-apx at local optimum:
\begin{itemize}
\item Search space consists of all subsets of facilities.
\item Fitness function is the same as in problem statement.
\item Valid step is of one of the forms:
	\begin{itemize}
	\item insert one facility to the set
	\item delete one facility from the set
	\item swap one facility from the set with one from outside the set.
	\end{itemize}
\end{itemize}

We have implemented 2 variants of Walkers (see: Local Search Framework design)
for this algorithm:
\begin{itemize}
\item RandomStepWalker: take a random valid step and calculate fitness: $\Oh(|F||C|)$ per iteration
\item BestStepWalker: find the fittest step among the valid ones: $\Oh(|F|(|F|+|C|))$ per iteration
\end{itemize}

In both cases, time of single iteration is proportional to the problem
instance size. It is therefore necessary to start the local search from
the solution relatively close (in the topology described) to the local
optimum. Intuitively the optimal solution will consist of a small number
of facilities (especially for test cases with uniformly distributed facilities and cities),
therefore the initial solution has been set to an empty set.

\section{\label{MCTS_FL}Monte Carlo Tree Search}

We will refer to the concepts and definitions introduced in MCTS design
chapter. Let us remind that the only domain-dependent concepts in our MCTS
framework are Move and State and the former is completely dependent on the
latter.

Because MCTS involves selecting decisions step by step we decided to transform our
standard Facility Location problem into Online Facility Location problem.
\begin{itemize}
\item State is a vector of already opened facilities and an ordering in which
next facilities will be processed.
\item Initial State is empty vector (opened facilities) and a permutation
of $1,2,\dots, |F|$ (ordering).
\item Move represent a choice if facility should be opened in given point or not.
\item Terminal state is when all facilities have been processed (each one is
considered only once).
\item Fitness of terminal State is equal to sum of openning costs and connection costs.
\item Fitness estimate is calculated using Adam Meyerson's algorithm\footnote{\url{http://www.cs.ucla.edu/~awm/papers/ofl.pdf}}
which is constant competitive for randomized input.
\end{itemize}

\section{Random Search}

As an additional benchmark for evaluating algorithms' performance, we've implemented
random search, which simply samples solution space at random. Solutions are drawn as follows:
\begin{itemize}
\item draw with uniform distribution the solution size $n \in \{1..|F|\}$.
\item draw $n$ times a facility with uniform distribution.
\item solution is the set of facilities from the previous point.
\end{itemize}

We've empirically shown for the benchmark problem instances, that the near optimal
solutions are small sets. This drawing algorithm is flexible enough to take it
into consideration.

\section{Benchmarks}
To evaluate the algorithms quality we have used UflLib\footnote{\url{http://www.mpi-inf.mpg.de/departments/d1/projects/benchmarks/UflLib/Euklid.html}}
and our "clustered tests". The need for "clustered tests" raised from observation that
uniform distribution is not natural for many real-world situation like city placements
e.g. normally cities are "clustered" around natural resources.

\subsection{Clustered tests}

Clustered tests are euclidian plane tests.
All facilities and cities are placed in the $[0,1]^2$ square.
Test generation begins with drawing the clusters.
Cluster is a rectangle, whose dimensions are drawn uniformly from the test case specific ranges (usually from $.1$ to $.4$).
Cluster positions are drawn so that the whole cluster fits into the unit square.
Number of clusters is test specific (from 10 to 30). Clusters can overlap.
Once the clusters are determined, facilities and cities are being drawn (their number is test specific; usually about ~100 facilities and ~1000 cities).
For each facility/city the cluster it will fall in is drawn with uniform probability.
The actual position is selected with uniform probability from the cluster rectangle.
Sample tests are depicted on figures \ref{FLClustered/test2.txt}-\ref{FLClustered/test4.txt}.

\input{../FLClustered/test0}
\input{../FLClustered/test2}
\input{../FLClustered/test4}

\section{Results}

\subsection{Best Step \& Random Step local searches}

From the definition
Best Step and Random Step local searches operate on the same topology and
they only differ by the way they are looking for the next step.

Random step (as the name suggests) browses the neighbours at random,
which suggests that is should be harder to get trapped at a local optimum.
The problem is that recalculating fitness requires $O(|F||C|)$ time which
seems to be much too much, considering that we modify not more than 2 
facilities. It is simple to reduce the complexity to $O(|C|\log(|F|))$,
but it would require to use heap (or any other collection with fast access
to the smallest element) but the constant factor overhead would definitely
balance out the complexity gain, since number of facilities in our test
cases is of the order of $100$.

Since it is hard to speed up the fitness recalculation, we've applied
another modification: it occurs that it is easy to browse all neighbouring
solutions in basically the same amount of time. We've named this approach
as Best Step local search. All in all a single iteration of our implementation
of Best Step is about 3 times slower than the random step one.
Code complexity is also higher since we have to smartly utilitize the
time to calculate all fitness changes at once.
Moreover, best step strategy is deterministic once we select the initial
solution.

Comparison of convergence speed of both algorithms is presented on diagrams.
Diagram \ref{fl_conv0} compares convergence of both algorithms on one of our clustered tests
and diagram \ref{fl_conv6} on a sample UflLib test case. Their behaviour on all UflLib Euclid
tests and clustered tests is roughly the same.

We can observe that both algorithms converge after about 30 iterations for test cases with
100 facilities. Best Step has a smooth curve (fitness is "continuous" in topology used).
Random Step curve is more rough - as the iterations pass, the fraction of neighbours with better fitness
falls much faster than the fitness gradient at the current solution.
Best Step finds better solutions than Random Step in every case and behaves more predictably,
and therefore only Best Step local search has been included to the general comparison.

\FloatBarrier
\input{../results/facility_location/ls_convergence/c0}
\input{../results/facility_location/ls_convergence/c6}
\FloatBarrier

\begin{figure}[ht]
  \input{../results/facility_location/comparison/EuclS}
\end{figure}

\subsection{MCTS}

For the reference about row names and overall concept first look onto MCTS description in its own chapter.
Columns are titled with $<samples\_multiplayer>$. \\
Description of used algorithm can be found in \ref{MCTS_FL}. \\
Number of iterations at each node of tree is $<samples\_multiplier> \cdot <number\_of\_left\_decisions>$.
From this alone it clearly follows that running time is proportional to the $<samples\_multiplier>$.

\FloatBarrier
\begin{figure}[ht]
  \input{../results/facility_location/mcts/1011EuclS.tex}
  \caption{Comparision of policies for 1011EuclS test case}
\end{figure}

\begin{figure}[ht]
  \input{../results/facility_location/mcts/1111EuclS.tex}
  \caption{Comparision of policies for 1111EuclS test case}
\end{figure}

\begin{figure}[ht]
  \input{../results/facility_location/mcts/2211EuclS.tex}
  \caption{Comparision of policies for 2211EuclS test case}
\end{figure}
\FloatBarrier

From the numbers we can clearly see that $PolicyRandMean$ gives the best answer.
This is not a surprise as our problem is kind of continous, so intuively it's better
to go where we have a big chance of getting good answer instead of going in direction
where we can get better result but with a much lower chance. \\
As we can see raising $samples\_multiplier$ doesn't affect answer significantly on the other hand
it increases running time dramatically. The running time of single testcase with $samples\_multiplier$
set to 10 took around 1 second and when set to 5000 took about 500 seconds. \\
From this we can see that best results are achieved with $PolicyRandMean$ with $samples\_multiplier$ set to low number. \\
The conclusions here are very similar to the results in TSP chapter. 
