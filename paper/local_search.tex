\chapter{Local Search Framework design}

\section{Motivation}

Local search\footnote{\url{http://en.wikipedia.org/wiki/Local_search_(optimization)}} is a metaheuristic for solving optimisation problems.
It is especially useful when the fitness function's local optima have value close to the global one.
Once a decent topology on the solution space is defined, the algorithm itself is very easy to implement:
you just make a walk in the solution space, choosing every step so that the next solution you move to has
a better fitness than the previous one. The local search implementation has usually just a few dozens of lines and
yet it can generate a series of problem, which usually stay unnoticed:
\begin{itemize}
\item it is hard to test a local search; local searches are prone to bugs:
	\begin{itemize}
	\item correct implementation does not guarantee that the result will be optimal
	\item there is usually no objectively good benchmark instances for problems to which local search is applied
	\item quality of the solution usually strongly depends on the amount of available computational power
	\item nobody bothers to write a decent testing framework (since every local search implementation is different).
		As a result tests are run by hand, which makes testing prone to human errors (we can easily lose repetitiveness of the results).
	\end{itemize}
\item some parts of code are rewritten in every implementation:
	\begin{itemize}
	\item execution time control
	\item main local search loop
	\item fitness monitoring
	\item step decision making strategy
	\end{itemize}
	Every single of them takes not much code which is hard to generalise anyway.
	However, it is easy to make a bug in these places, which can stay unnoticed for a long time.
\end{itemize}

We've made an attempt to implement a C++ local search 
framework addressing these issues.

\section{General description}

Local Search Framework is supposed to automatise the process of writing local searches with no execution overhead due to the framework code.
Framework should be responsible for making consistent decisions about the issues that are not influencing the algorithm itself
(for example results logging, repetitive testing, limiting execution time) and allow to avoid rewriting repetitive code.
As the concept of local searches is really simple, our design has to be easily comprehensible and super intuitive.
It definitely shouldn't force user to bend/hack the solution to fit the framework.

We use templates and concepts to avoid any overhead in the execution time and allow maximum flexibility.

\section{Main function}

The outer interface of the framework consists of a single template function search().
Its code is explicitly stated in the design - user {\bf has to know} this piece of code before using the framework.
The order of actions performed is vital for utilisation of the framework.
Therefore search() has to be simple and readable for an average user.

We assumed that the fitness of the solution can be efficiently calculated and represented as a floating point number.
We believe that imposing the fitness type across the framework is a useful simplification and prevents any type
conversion problems in this context. In the current version fitness type is set to double which is disputable but convenient.

search() doesn't know the nature of the problem.
It is due to the fact that we wanted to extract problem independent components.

Note that search() receives a logger fulfilling the Logger concept defined in the Algorithm
results' presentation framework.


\begin{lstlisting}
template<typename Walker, typename StepCtrl, typename ProgressCtrl,
	typename Random, typename Logger>
void search(Walker &walker, StepCtrl &step_ctrl, ProgressCtrl &progress_ctrl,
	Random &random, Logger &logger)
{
	while(1)
	{
		double current_fitness = walker.current_fitness();
		logger.log(current_fitness);
		double progress = progress_ctrl.progress(current_fitness);
		if(progress>=1) break;
		walker.prepare_step(progress,random);
		if(step_ctrl.step_decision(current_fitness,walker.next_fitness(),
			progress,random)) walker.make_step();
	}
}
\end{lstlisting}

\section{Concepts}

\subsection{Walker}

Walker is the only component which knows the nature of the problem.
It is not divided on this framework level, since if more components would know about the problem it would create cross dependencies.
In other words, such situation would inevitably make search() transfer problem specific data between them.
Also many custom/intrusive optimisation can be made at this point, so we believe that this is definitely a point at which we should allow the user to plug in
his own code. \\
Walker is responsible for:
\begin{itemize}
\item maintaining the current solution
\item preparing the proposition of a new step
\item making the proposed step
\end{itemize}
It has to contain an initial solution before calling search().
Better solutions have lower fitness.

\subsection{ProgressCtrl}

ProgressCtrl (Progress Controller) controls the execution time of the
local search. It is responsible for estimation of the ratio: iterations
passed/iterations available.

It is usually implemented as a time/iteration limit or solution sufficiency threshold.
None of these are problem dependent, hence this component can be effectively extracted from the design.

\subsection{StepCtrl}

StepCtrl (step controller) represents the metaheuristic chosen to
solve the problem. It is responsible for making decision whether to
make the step proposed by Walker.
Simulated annealing and hill climb have easy/trivial implementations of this concept.

\subsection{Random}

It is just C++11 RNG (random nubmer generator) concept.
Random generates random integer values.
It is explicitly shared between components of the search() for the following reasons:
\begin{itemize}
\item we assume that we receive only one seed from the outside
\item using many generators at once (especially with the same seed) may create undesired conditional probabilities
\end{itemize}

\section{Reasoning}

We have considered alternative approaches to the proposed design, they are
worth studying in order to identify possible problems and why current design
solves them in our opinion.

\subsection{Abstract representation}
It is helpful to express structure of local search framework in terms of a
graph where each node represents a separated concept and an edge $A \to B$
exists iff concept $A$ uses (e.g. calls, owns, reads data) concept $B$. First
assumption was that resulting graph is compact, local search algorithm provided
by the framework should be seen as one phase from the outside (e.g. invocation
of one function, which takes input and returns result), so every concept in
different connected component than the algorithm itself is useless. We will
refer to described graph as the \emph{component graph}.

\subsection{The way to the tree}
We have eliminated all designs with cycles in component graph, the most
important reason for this was that we could not find how we can benefit from
allowing two way communication between components. Furthermore all concepts
need to be initialised either by the user or search procedure itself if they are
completely algorithm independent (like statistics gathering) and every cycle
makes initialisation really complicated, there is no arbitrary choice of
initialisation order we could come up with in this case.

Therefore we were free to choose either general DAG or a tree (we were aiming
for the latter). To reduce both of them to the second one we can run
depth-first search from algorithm's entry point (the search() procedure), which
becomes a root of a depth-first spanning tree. The only difference between the
graph being a general DAG and a tree is manifested by the presence of non-tree
edges. Our graph is acyclic, so we will not find back edges.

Please note that presence of back edges would mean that execution flow can be
returned to caller for a moment and then returned back to the callee
automatically - this can obviously be replaced by making communication
passive, caller provides all data needed do execute call (query) and expects
response, every query is initiated by caller and completed by callee using
provided data.

\subsection{Forward edges elimination}
Any forward edge means that we are skipping many abstraction layers with an
invocation. Obviously this can be avoided by passing a call through all layers
that are bypassed by a forward edge. We replace forward edge with the composition
of facades. Modern C++ compilers can easily inline such constructions, so that
the forward edge will not be present in design and C++ code, but will be
generated by compiler for performance reasons.

Moreover every forward edge means that at least two different concepts need to
know (the same) type of called concept, we think it is less convenient during
initialisation, however in this specific case a concept can inherit type from
its predecessor in the spanning tree (as long as the former is not initialised
by a user).

We have made an experiment with changing parts of an algorithm (namely
underlying data structure) during algorithm execution. Obviously allowing
forward edge in this case (calling specific data structure directly, skipping
its owner) might invalidate algorithm. The real problem here is a careless user
who gave an ownership to the object being descendant of a caller while allowing
forward edges in the component graph. Removing forward edge as described above
forces every call to pass through data structure owner, which is less
error-prone and simpler.

We further assume that there are no forward edges in the graph.

\subsection{Cross edges discussion}
Consider the case where one concept $C$ is a child of two (or more) concepts
$A$ and $B$ (assume $B \to C$ is a cross edge). Let $P$ be the lowest common
ancestor of both $A$ and $B$ in depth-first spanning tree of the component
graph. Described situation breaks composability of algorithm's design but one
can easily come up with an example of a local search algorithm where such
design is desired, we will discuss it later, for now let us assume that we do
need communication between components as described above.

If we disallow cross edges in our design we have to provide a different mechanism
of communication between $B$ and $C$. As the graph without cross edges is a
tree we have to pass data back (query result) from $C$ to $P$ and provide $B$
with it in a separate call. The obvious problem here is that data format must be
known to all concepts on paths from $B$ and $C$ do $P$ (including $P$) and data
format type can (in most cases will) be domain dependant - therefore we are
raising domain boundary up to the lowest common ancestor of components that were
connected by cross edge. This means that protocol common to $B$ and $C$ (which
may change) must be propagated during initialisation down in the tree starting
from $P$.

The obvious benefits from treelike component graph is simple. In the top-down
initialisation, we can assume that during construction of algorithm, child being
initialised is given an interface to obtain initialisation data from parent
according to its needs or this data is passed explicitly. Furthermore there is
no problem with assigning an ownership of a concept. Tree design makes
synchronisation model extremely easy to implement in case one would like
concepts to operate concurrently.

There are more problems with cross edges. Initialisation cannot be done
top-down in described automatic fashion, ownership assignment just like the
rest of the initialisation procedure needs to be done by the user as hidden
dependencies are not obvious to any automatic model. It is pretty obvious that
the less constraints we put on algorithm's design the less we know and the more
must be done manually.

It turned out that in the case of local search framework both performance
considerations and limiting domain-dependency required nearly the same
transformations of component graph, which resulted in the graph becoming a
tree. Cross edges were eliminated by encoding entire problem specific
components in the Walker concept. Topologies of solution spaces implied by
problems discussed when designing this framework vary considerably, we were
unable to split this concept leaving the complexity of single step unchanged for
studied examples.

\section{Framework supplied implementations}

\subsection{ProgressCtrl implementations}
\begin{itemize}
\item IterationCtrl - fixes the number of search iterations.
\item TimeCtrl - fixes the time of search execution up to to the fixed granularity.
	Granularity is the amount of iterations between the consecutive time checks.
	Checking time every iteration is too expensive if expected single iteration time
	is very short.
\item TimeAutoCtrl - same as TimeCtrl but the granularity is being adjusted
	automatically using linear regression. The aimed gap between time checks has
	been hardcoded to $0.01s$.
\end{itemize}

\subsection{StepCtrl implementations}
\begin{itemize}
\item HillClimb - accepts a step if the next fitness is better than the current fitness.
\item Annealing - makes a decision according to the temperature schedule defined by
	\mbox{Boltzmann} distribution\footnote{\url{http://en.wikipedia.org/wiki/Boltzmann_distribution}}.
\end{itemize}

\subsection{Walker implementations}
Particular walkers are described in the chapters about the problems they operate on.
\begin{itemize}
\item TSP: TwoOptWalker
\item UFL: BestStepWalker, RandomStepWalker
\item Steiner Forest: BreakCycleWalker, ActiveVerticesWalker
\end{itemize}

