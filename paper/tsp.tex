\chapter{Metrical TSP algorithms}


\section{Problem description}

\defproblem{ Metrical Travelling Salesman Problem}
{ Complete graph $G = (V,d)$, where $d:V \times V \to\mathbb{R}$ is a metric. }
{ What is the shortest cycle in $G$ which comes through every vertex exactly once? }

See link\footnote{\url{http://en.wikipedia.org/wiki/Travelling_salesman_problem}}
for detailed description.

\section{Christofides 1.5-apx}
Christofides algorithm\footnote{\url{http://en.wikipedia.org/wiki/Christofides_algorithm}} is designed to work with instances of TSP whose edge
weights satisfy triangle inequality. Let $G=(V, w)$ be an instance of TSP,
the algorithm consists of four steps:
\begin{enumerate}
\item Create minimum spanning tree $T$ for graph $G$. \\
Here we have implemented $\Oh(n^2)$ Prim's algorithm\footnote{\url{http://en.wikipedia.org/wiki/Prim's_algorithm}}.
Although for Euclidean spaces there exists faster $\Oh(n\log(n))$ algorithm, the overall gain
would be insignificant so we didn't use it.
\item Let $O$ be a set of odd degree vertices in $T$.
	  Find minimum perfect matching $M$ in complete graph over $O$. \\
For this part we have used \emph{Blossom V} \cite{BlossomV}
implementation of Edmond's Blossom algorithm\footnote{\url{http://en.wikipedia.org/wiki/Blossom_algorithm}}.
Worst case running time of this part is $\Oh(|O|^5)$ but in average case it behaves very well.
\item Combine edges of $M$ and $T$ to form a multigraph $H$.
\item Find Eulerian circuit $E$ in $H$. ($\Oh(|H|)$).
\item Make $E$ Hamiltonian by shortcutting visited nodes. ($\Oh(|E|)$).
\end{enumerate}
Summing this up, our implementation in worst case needs $\Oh(|V|^5)$ time but generally
is fast in comparison to our other techniques.

\section{2opt Local Search}

In 2-opt\footnote{\url{http://en.wikipedia.org/wiki/2-opt}} local search for TSP, a single step
consists of reverting a segment of the current cycle. Intuitively, we find a point
at which the route crosses over itself and reorder it so that it doesn't.

Since in metrical TSP distance between a pair of points is the same for both directions,
computing fitness of the new route simplifies to removing a pair of edges and replacing it with another
pair.

We've tested 3 different structures for maintaining the current local search solution:
\begin{itemize}
\item array of vertices in order as they appear on the cycle.
\item Reversible Segment List\footnote{\url{http://www.hars.us/Papers/revi.pdf}}
\item Augmented splay tree.
\end{itemize}
\begin{figure}[!h]
\begin{tabular}{c|cc}
& vertex read cost & reverse cost \\\hline
array & $\Oh(1)$ & $\Oh(|V|)$ \\
RSL & $\Oh(\sqrt{|V|})$ & $\Oh(\sqrt{|V|})$ amortized \\
splay & $\Oh(\log(|V|)$ amortized & $\Oh(\log(|V|))$ amortized
\end{tabular}
\end{figure}
In our implementation segment to reverse is selected with uniform probability,
excluding the degenerated cases -- set of cycle edges has to actually change.
Evaluating fitness of neighbouring solution drawn requires to read vertices
on 4 positions in the cycle. The number of fitness evaluations dominates
the number of the actual reverses in the long run due to the fact that it
becomes harder and harder to find a neighbour with better fitness as we approach
the local optimum. As a consequence we have empirically observed that out of
3 data structure mentioned, the array performed best on TSPLIB (see Benchmarks)
test cases.

\section{Monte Carlo Tree Search}
We will refer to the concepts and definitions introduced in MCTS design
chapter. Let us remind that the only domain-dependent concepts in our MCTS
framework are Move and State and the former is completely dependent on the
latter.

It is widely known from games solving applications of MCTS method that we
should choose State implementation which minimizes branch factor of the resulting
search tree. For TSP problem we chose path building approach:
\begin{itemize}
  \item State is a path with arbitrary start point (permutation of a subset of
    all vertices)
  \item initial State is an arbitrary chosen start vertex
  \item Move represents choosing from remaining vertices the next one to be
    added to the end of the path
  \item terminal State is reached when all vertices are in the path
  \item Fitness of terminal State is equal to the cost of a Hamilton cycle, note
    that path defines a permutation of vertices and distance function is a proper
    metric
  \item Fitness estimate is a fitness of terminal state reached after applying
    a sequence of random decisions
\end{itemize}

We have introduced two improvements to the above schema. In order to reduce branch
factor of resulting tree we have a limited number of vertices taken into
consideration when choosing next move. A good heuristics here is to choose from
no more than $K$ vertices closest to the path's end.

To improve accuracy of each sample we have decided to replace last $L$ random
moves with exhaustive search, therefore Fitness estimate is set to minimum of
fitnesses of all terminal states visited during this search. Typically $N$ is
very small, for implementation described above we have determined that the best
accuracy to performance ratio can be achieved when $N = 4$, it should be
obvious that $N$ depends on the State implementation rather than size of the
input graph. Note that this method works well with certain types of policies
and statistics aggregation methods as discussed in results overview.

\section{Benchmarks}
To evaluate the algorithms quality we have used
TSPLIB\footnote{\url{http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/}}
symmetrical instances.

\section{Results}

We have selected the best local search algorithm to compare it against the best
MCTS and Christofides implementations on a subset of TSPLIB instances.
Additional experiments were performed to choose optimal configuration of a
local search and tree search algorithms, the results of these tests are presented
later.

If $T$ is the running time of Christofides algorithm for given test instance
then the time limit for hill climb is set to $\max(T, 0.5 s)$ and for the tree
search is set to $\max(T, 5 s)$.

An $\infty$ in some cell means that no result could be obtained for given
instance using given algorithm within the time limit.

\begin{figure}[ht]
  \centering
  \input{../results/tsp/tsp_comparison/eil_graphs}
  \caption{Comparison of all implemented TSP algorithms.}
\end{figure}

MCTS algorithm for TSP performed poorly when compared to other implemented
methods. Extensive comparison was unfortunately impossible due to extremely
high computational cost of the tree search method for instances with
significant number of vertices. Most of performed experiments used the smallest
instances available in TSPLIB collection -- graphs with less than $300$
vertices. The most efficient MCTS algorithm (see next section for model
selection methodology) needed at least $5 s$ to find a solution which was
$1.2$-approximation, while local search algorithms were able to find a
better solution in a fraction of this time. Running the MCTS method
for medium-sized instances is impractical, for graphs with more than
$10000$ vertices it is impossible.

Poor overall performance of MCTS method in our tests is a bit surprising as
travelling salesman problem variations are presented as a primary non-games
application of this approach (see \cite{MCTSsurvey} for details). We believe
that just like in the case of SA, the search space is too ,,smooth'' and
instead of making refined decisions one should check as many points as possible
within given time limit.

Our experiments showed that a simple hill climb local search heuristic performs
as well as Christofides algorithm. Given the complexity level of the latter
(finding a perfect matching with minimum weight) we can see no need to use
anything more complicated than a hill climb method for the symmetric metrical
TSP problem in practical applications.

\subsection { 2-opt hill climb \& simulated annealing }
In this experiment we've shown that SA doesn't improve the results of the 2-opt.
Initial temperature has been set to mean edge cost of the initial solution.
Temperature falls geometrically over time reaching fixed final temperature at the last iteration.
Diagrams 4.1-3 present SA with different final temperatures ($10^{-2}, 10^{-5}, 10^{-9}$) and
pure hill climb strategy on sample TSPLIB test cases.

\FloatBarrier
\begin{figure}[h]
\input{../results/tsp/ls_convergence/brazil58}
\end{figure}
\begin{figure}[h]
\input{../results/tsp/ls_convergence/d15112}
\end{figure}
\begin{figure}[h]
\input{../results/tsp/ls_convergence/ulysses22}
\end{figure}
\FloatBarrier

The first problem which has been observed is that calculating temperature for Boltzmann distribution is
expensive compared to a single iteration. We've dealt with it by updating temperature
only periodically. In our implementation mean SA iteration is about $30\%$ slower than
hill climb iteration. This fact hadn't been depicted in the diagrams in any way.

We can observe that hill climb converges strictly faster than any SA variant.
Moreover, the fitness curve is smooth (even though the neighbourhood is being browsed at random),
which means that not only 2-opt topology doesn't have many local optima but also that the
fitness function is ,,continuous'' in it.

Basing on these observations, we are not considering 2-opt SA a
suitable solution for TSP and have removed it from the general tsp comparison.

\subsection{Monte Carlo Tree Search policies}

Despite the poor performance of MCTS-based algorithms for TSP problem, we have
compared policies described in previous sections on small instances from
TSPLIB. The results are presented below. Each row corresponds to a single
policy (for names explanation please refer to the proper chapter). Each column
corresponds to the State representation being used. Column description has a
format \verb+<graph name>, limit <moves limit>+ where \emph{moves limit} is
the limit of the number of vertices taken into consideration when choosing next
move as described before. Number in each cell is equal to the final solution's
fitness.

The rest of configuration of each algorithm is exactly the same. In each test
run the algorithm performs $500$ times the current number of vertices not in
the path samples per single decision.

\FloatBarrier
\begin{figure}[ht]
  \centering
  \input{../results/tsp/mcts_policies_comparison/eil51}
  \caption{Comparison of MCTS policies for TSP on eil51 instance.}
\end{figure}

\begin{figure}[ht]
  \centering
  \input{../results/tsp/mcts_policies_comparison/eil76}
  \caption{Comparison of MCTS policies for TSP on eil76 instance.}
\end{figure}

\begin{figure}[ht]
  \centering
  \input{../results/tsp/mcts_policies_comparison/eil101}
  \caption{Comparison of MCTS policies for TSP on eil101 instance.}
\end{figure}
\FloatBarrier

The results of this comparison were used while choosing the best algorithm's
configuration for other tests. We could also confirm a few observations made
during the course of fine-tunning our implementation.

Policies which choose the best node by minimizing expected fitness of a
solution outperform ones which minimize the lowest observed fitness and the
difference between them becomes smaller when the tree branch factor is being
reduced by restricting moves considered at each step. This can be heuristically
explained as a consequence of a performing exhaustive search when the size of
reachable solution's space is small enough (that means a few decisions before
reaching the terminal state). Once we are sure that after reaching a subtree
which is small enough we will find an optimal solution reachable from its root,
our objective is slightly different. Instead of looking for the best solution
we look for a subtree with pretty low fitness of reachable solutions in hope
that during the exhaustive search we will find better terminal state than we
have seen anytime before. We have made another observation which confirms above
conclusion. According to our tests the lowest fitness of any terminal state
reached during random sampling procedure is $5\% - 20\%$ higher than fitness of
the best state found during the final exhaustive search in the same run of an
algorithm.

Please note that the same pattern reproduces itself if one does not perform the
final exhaustive search. The main reason is that when the algorithm descends
into really small search subtree (say $6$ decisions before reaching the
terminal state) and the tree itself is highly uniform (estimates for each
child of a given node are roughly the same) all strategies reduce to picking a
random path to some terminal state. When the number of samples per decision
exceeds the number of different terminal states the random sampling procedure
will visit all of them with high probability. The sole purpose of introduced
modification (the exhaustive search procedure) is to speed up the entire process
and make sure that no matter how unlucky we are, we will always find the best
solution.

One can easily see that as far as the choice of the next node in the sampling
procedure is concerned there is no better strategy than uniform sampling. This
method is also the fastest one and its performance does not degrades when the
number of possible moves at each state (or a branch factor of the search tree)
increases. When one develops an algorithm which has a lot of magic constants
that affect its behaviour the problem of finding the best set of parameters
becomes nontrivial, uniform sampling is superior in this case as it guarantees
reasonable results without any fine tuning.

Note that the policies which prefer so-far-the best subtree during the random
sampling do not scale well when the branch factor of the search tree increases.
We suspect that these policies are completely useless for approximating
solution for instances with more than $100$ vertices as limiting the branch
factor greatly reduces reachable search space. Dramatically bad performance of
\emph{PolicyEpsBest} can be easily explained given the previous observations.
This policy not only seeks for a single best solution, which we already
investigated to be a bad idea, but also once a solution with low (but still far
from optimal) fitness is found in one subtree, the algorithm tends to visit
this subtree and greatly reduces chances of correcting this mistake.
